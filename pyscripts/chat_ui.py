import streamlit as st
import uuid
import os
import hashlib
from openai import OpenAI, AuthenticationError, APIError

# ç”Ÿæˆæˆ–è·å–ç”¨æˆ·ç‰¹å®šçš„ä¼šè¯ID
if 'user_session_id' not in st.session_state:
    st.session_state.user_session_id = str(uuid.uuid4())

# ä½¿ç”¨ç”¨æˆ·ä¼šè¯IDæ¥è·å–æˆ–åˆå§‹åŒ–ç”¨æˆ·ç‰¹å®šçš„æ•°æ®
def get_user_data():
    if 'user_data' not in st.session_state:
        st.session_state.user_data = {}

    if st.session_state.user_session_id not in st.session_state.user_data:
        st.session_state.user_data[st.session_state.user_session_id] = {
            'messages': [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜ã€‚"}
            ],
            'uploaded_files': [],
            'api_key': 'sk-',
            'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
            'model_name': 'deepseek-r1',
            'past_sessions': []
        }

    return st.session_state.user_data[st.session_state.user_session_id]

# æ›´æ–°ç”¨æˆ·æ•°æ®çš„è¾…åŠ©å‡½æ•°
def update_user_data(key, value):
    user_data = get_user_data()
    user_data[key] = value

# ä¿å­˜å½“å‰ä¼šè¯
def save_current_session():
    user_data = get_user_data()
    if len(user_data['messages']) > 1:  # åªæœ‰å½“æœ‰å®é™…å¯¹è¯æ—¶æ‰ä¿å­˜
        current_session = {
            'id': st.session_state.user_session_id,
            'messages': user_data['messages']
        }
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„ä¼šè¯ï¼Œå¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥
        existing_session = next((session for session in user_data['past_sessions'] if session['id'] == current_session['id']), None)
        if existing_session:
            existing_session.update(current_session)
        else:
            user_data['past_sessions'].insert(0, current_session)
        # é™åˆ¶ä¿å­˜çš„ä¼šè¯æ•°é‡ï¼Œä¾‹å¦‚åªä¿ç•™æœ€è¿‘çš„5ä¸ªä¼šè¯
        user_data['past_sessions'] = user_data['past_sessions'][:5]

# åŠ è½½é€‰å®šçš„ä¼šè¯
def load_session(session_id):
    user_data = get_user_data()
    for session in user_data['past_sessions']:
        if session['id'] == session_id:
            st.session_state.user_session_id = session_id
            st.session_state.user_data[session_id] = {
                'messages': session['messages'],
                'uploaded_files': [],
                'api_key': user_data['api_key'],
                'base_url': user_data['base_url'],
                'model_name': user_data['model_name'],
                'past_sessions': user_data['past_sessions']
            }
            break


def save_uploaded_files(upload_dir, uploaded_files):
    """ä¿å­˜ä¸Šä¼ çš„ txt å’Œ markdown æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•å¹¶è¿”å›æ–‡ä»¶ä¿¡æ¯"""
    user_data = get_user_data()
    saved_files = []
    current_files = [f["name"] for f in user_data['uploaded_files']]

    for file in uploaded_files:
        if file.name in current_files:
            continue

        if not file.name.lower().endswith(('.txt', '.md', '.markdown')):
            st.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.name}ã€‚è¯·ä¸Šä¼  .txt æˆ– .md æ–‡ä»¶ã€‚")
            continue

        if file.size > 1 * 1024 * 1024:  # 1MBé™åˆ¶
            st.error(f"æ–‡ä»¶ {file.name} è¶…è¿‡å¤§å°é™åˆ¶ï¼ˆ1MBï¼‰")
            continue

        try:
            # ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
            file_path = os.path.join(upload_dir, file.name)
            with open(file_path, "wb") as f:
                f.write(file.getbuffer())

            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, "r", encoding='utf-8') as f:
                content = f.read()

            # ç”Ÿæˆå†…å®¹å“ˆå¸Œå€¼
            content_hash = hashlib.md5(content.encode()).hexdigest()

            # æ£€æŸ¥é‡å¤å†…å®¹
            if any(f["hash"] == content_hash for f in user_data['uploaded_files']):
                st.info(f"æ–‡ä»¶ {file.name} çš„å†…å®¹ä¸å·²ä¸Šä¼ çš„æ–‡ä»¶é‡å¤ï¼Œå·²è·³è¿‡ã€‚")
                continue

            saved_files.append({
                "name": file.name,
                "content": content,
                "size": file.size,
                "hash": content_hash
            })
            st.success(f"æˆåŠŸä¸Šä¼ æ–‡ä»¶: {file.name}")

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {str(e)}")
            continue

    return saved_files

def format_file_contents(files):
    return "\n".join([f"=== {f['name']} ===\n{f['content']}\n" for f in files])

def get_active_api_config():
    user_data = get_user_data()
    return user_data['base_url'], user_data['api_key'], user_data['model_name']

def process_stream(stream):
    """åˆå¹¶å¤„ç†æ€è€ƒé˜¶æ®µå’Œå“åº”é˜¶æ®µ"""
    thinking_content = ""
    response_content = ""

    # åœ¨çŠ¶æ€å—å¤–éƒ¨é¢„å…ˆåˆ›å»ºå“åº”å ä½ç¬¦
    response_placeholder = st.empty()

    with st.status("æ€è€ƒä¸­...", expanded=True) as status:
        thinking_placeholder = st.empty()
        thinking_phase = True  # æ€è€ƒé˜¶æ®µæ ‡è®°

        for chunk in stream:
            # è§£ææ•°æ®å—
            delta = chunk.choices[0].delta
            reasoning = delta.reasoning_content if hasattr(delta, 'reasoning_content') else ""
            content = delta.content if hasattr(delta, 'content') else ""
            role = delta.role if hasattr(delta, 'role') else ""

            # å¤„ç†æ€è€ƒé˜¶æ®µ
            if thinking_phase:
                if reasoning:
                    thinking_content += reasoning
                    thinking_placeholder.markdown(f"æ€è€ƒè¿‡ç¨‹ï¼š\n{thinking_content}")

                # æ£€æµ‹æ€è€ƒé˜¶æ®µç»“æŸ
                if content:
                    status.update(label="æ€è€ƒå®Œæˆ", state="complete", expanded=False)
                    thinking_phase = False
                    response_placeholder.markdown("å›ç­”ï¼š\nâ–Œ")  # åˆå§‹åŒ–å“åº”å…‰æ ‡

            # å¤„ç†å“åº”é˜¶æ®µï¼ˆæ— è®ºæ˜¯å¦åœ¨æ€è€ƒé˜¶æ®µéƒ½æ”¶é›†å†…å®¹ï¼‰
            if content:
                response_content += content
                if not thinking_phase:
                    response_placeholder.markdown(f"å›ç­”ï¼š\n{response_content}â–Œ")

        # æµç»“æŸåç§»é™¤å…‰æ ‡
        response_placeholder.markdown(f"å›ç­”ï¼š\n{response_content}")

    return f"{thinking_content}{response_content}"

def display_chat_history():
    user_data = get_user_data()
    for message in user_data['messages']:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

def handle_user_input():
    user_data = get_user_data()
    base_url, api_key, model_name = get_active_api_config()

    if not api_key or api_key == 'sk-':
        st.error("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„ API Keyã€‚")
        return

    try:
        client = OpenAI(api_key=api_key, base_url=base_url)

        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶ï¼ˆæ”¯æŒ .txt å’Œ .mdï¼‰",
            type=["txt", "md", "markdown"],
            accept_multiple_files=True,
            key="file_uploader"
        )

        if uploaded_files:
            new_files = save_uploaded_files(dirs, uploaded_files)
            user_data['uploaded_files'].extend(new_files)

        user_content = []
        if user_input := st.chat_input("è¯·é—®æˆ‘ä»»ä½•äº‹!"):
            user_content.append(user_input)

            if user_data['uploaded_files']:
                file_content = format_file_contents(user_data['uploaded_files'])
                user_content.append("\n[ä¸Šä¼ æ–‡ä»¶å†…å®¹]\n" + file_content)
                user_data['uploaded_files'] = []  # æ¸…ç©ºå·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨

            full_content = "\n".join(user_content)

            user_data['messages'].append({"role": "user", "content": full_content})
            with st.chat_message("user"):
                st.markdown(user_input)

            with st.chat_message("assistant"):
                try:
                    stream = client.chat.completions.create(
                        model=model_name,
                        messages=user_data['messages'],
                        stream=True
                    )
                    response = process_stream(stream)
                    user_data['messages'].append(
                        {"role": "assistant", "content": response}
                    )
                except AuthenticationError:
                    st.error("API è®¤è¯å¤±è´¥ã€‚è¯·æ£€æŸ¥æ‚¨çš„ API Key æ˜¯å¦æ­£ç¡®ã€‚")
                except APIError as e:
                    st.error(f"API é”™è¯¯: {str(e)}")
                except Exception as e:
                    st.error(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")

    except Exception as e:
        st.error(f"è®¾ç½® OpenAI å®¢æˆ·ç«¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

def main_interface():
    st.title("AI åŠ©æ‰‹")
    user_data = get_user_data()

    with st.sidebar:
        api_key = st.text_input("API Key", user_data['api_key'], type="password")
        if api_key:
            update_user_data('api_key', api_key)
        else:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ API Key")

        # Base URL é€‰é¡¹
        base_url_options = {
            "DashScope": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "ARK": "https://ark.cn-beijing.volces.com/api/v3",
            "è‡ªå®šä¹‰": "custom"
        }
        selected_base_url = st.selectbox(
            "é€‰æ‹© Base URL",
            options=list(base_url_options.keys()),
            index=list(base_url_options.keys()).index("DashScope") if user_data['base_url'] == base_url_options["DashScope"] else 0
        )
        if selected_base_url == "è‡ªå®šä¹‰":
            custom_base_url = st.text_input("è‡ªå®šä¹‰ Base URL", user_data['base_url'])
            update_user_data('base_url', custom_base_url)
        else:
            update_user_data('base_url', base_url_options[selected_base_url])

        # Model Name é€‰é¡¹
        model_options = {
            "deepseek-r1": "deepseek-r1",
            "deepseek-v3": "deepseek-v3",
            "è‡ªå®šä¹‰": "custom"
        }
        selected_model = st.selectbox(
            "é€‰æ‹© Model",
            options=list(model_options.keys()),
            index=list(model_options.keys()).index("deepseek-r1") if user_data['model_name'] == "deepseek-r1" else 0
        )
        if selected_model == "è‡ªå®šä¹‰":
            custom_model = st.text_input("è‡ªå®šä¹‰ Model Name", user_data['model_name'])
            update_user_data('model_name', custom_model)
        else:
            update_user_data('model_name', model_options[selected_model])

        if st.button("ğŸ†• æ–°ä¼šè¯"):
            save_current_session()  # ä¿å­˜å½“å‰ä¼šè¯
            new_session_id = str(uuid.uuid4())
            st.session_state.user_data[new_session_id] = {
                'messages': [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œè¯·å›ç­”ç”¨æˆ·æå‡ºçš„é—®é¢˜ã€‚"}
                ],
                'uploaded_files': [],
                'api_key': user_data['api_key'],  # ä¿ç•™å½“å‰çš„ API Key
                'base_url': user_data['base_url'],  # ä¿ç•™å½“å‰çš„ Base URL
                'model_name': user_data['model_name'],  # ä¿ç•™å½“å‰çš„ Model Name
                'past_sessions': user_data['past_sessions']  # ä¿ç•™è¿‡å»çš„ä¼šè¯è®°å½•
            }
            st.session_state.user_session_id = new_session_id
            st.rerun()

        # æ˜¾ç¤ºè¿‡å»çš„ä¼šè¯
        st.write("è¿‡å»çš„ä¼šè¯ï¼š")
        for past_session in user_data['past_sessions']:
            if st.button(f"åŠ è½½ä¼šè¯ {past_session['id'][:8]}...", key=past_session['id']):
                load_session(past_session['id'])
                st.rerun()

    display_chat_history()
    handle_user_input()

def main():
    if 'user_session_id' not in st.session_state:
        st.session_state.user_session_id = str(uuid.uuid4())

    main_interface()

if __name__ == "__main__":
    dirs = 'uploads/'

    if not os.path.exists(dirs):
        os.makedirs(dirs)

    main()